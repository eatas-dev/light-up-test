{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain==0.3.14 in ./.venv/lib/python3.12/site-packages (0.3.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (3.11.11)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (0.3.4)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (0.2.10)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (2.10.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain==0.3.14) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.14) (1.18.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.14) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.14) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.14) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.14) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.14) (2024.12.14)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.14) (3.1.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (4.8.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain==0.3.14) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain==0.3.14) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-openai==0.2.14 in ./.venv/lib/python3.12/site-packages (0.2.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.27 in ./.venv/lib/python3.12/site-packages (from langchain-openai==0.2.14) (0.3.29)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in ./.venv/lib/python3.12/site-packages (from langchain-openai==0.2.14) (1.59.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.12/site-packages (from langchain-openai==0.2.14) (0.8.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (1.33)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (0.2.10)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (2.10.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (4.8.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (0.8.2)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.14) (2024.11.6)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.14) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (3.10)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.58.1->langchain-openai==0.2.14) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (3.10.13)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./.venv/lib/python3.12/site-packages (from langsmith<0.3,>=0.1.125->langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in ./.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.27->langchain-openai==0.2.14) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.14) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.14) (2.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: youtube-transcript-api in ./.venv/lib/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from youtube-transcript-api) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->youtube-transcript-api) (2024.12.14)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pytube in ./.venv/lib/python3.12/site-packages (15.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.3.14\n",
    "%pip install langchain-openai==0.2.14\n",
    "%pip install youtube-transcript-api\n",
    "%pip install pytube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "花風を引いてますけど鼻あ花風を引いて ますけどあのも題なくえっと問題ない問題 ないというかうん元気で元気ですよ少し だけ疲れてますけどそうなんですなんかで も前回よりげししてないですねあそうあの あの僕も思いましたなんか前回少し ふっくらしたなと思いましたでも体重は別 に増えたわけじゃ なく健康的な感じじゃないですかお そうですね確かにあの70は超えてない です69.何ぼとかって時々あるんです けどはい70はいかないですね68と69 の間を行ったり来たりしてますそうです なんか1番減った時とそんなに今変わって ないのではいやっぱ食べてるか食べてない かでねやっぱゲストリドが変わるんだなっ てすいませんあ本当ですね面白いです ね思いましたこんなに変るって今見て思い ます結構変わりやすいのかもしれないです ねそうれでくと確かに顔に出やすい方とか いらっしゃいますよ ねうんそうです多分ま僕嘘つけないタイプ な分顔に出るだと思いますそっちそっちの ですね本体調とかも全部顔出てああでも あの分かりやすくてれはいいです確か に確か にたと最近のお食事のはいまだ遅れて なかったんですけど奥さんにあの分析の 結果を出したの でしたいんだ えっとこの12123って書いてあんです が13なのかは日日が書いてなかったので ちょっと分からない状態ではい3日間3 日間です12とその間にあった食事の中で 朝晩ピックアップしてあと23日っていう 感じ あのしましたわかりましたはいなのでまだ こうあれですねあの回復してすぐのところ のお食事なので野菜の量としてはいつもの 量ではないていう158になってるの でちょっとあれあそうなんですまだやっぱ 食べないとなんですね野菜は結構多くなっ たと思ったんですけどあそうですか1番 食べてる時に比べる1番食べてる時だと 多分200とか250とか行ってるかなと 思うけどあそうなんですねはいちょっと 控えてた時期も含めてって感じなのでああ 分かりましたなるほど今の倍食べて いただいても300ちょっとなのであの倍 食べても大丈夫 ですそんなに食べれ ない本当ですかなんか割とあのやり始める と400とか行く方とかもいらっしゃるん ですよどうやって増やすんですかねその 自分自炊をしないからあありがとうやどう しようなんかあれですかね結構野菜サラダ 高いじゃないですかあのコンビニとかで 買うとはいだからあの袋のやつを買ったり してるんですけどはいあれを3袋食べれば いいのかもしあのなるほどそうですねあれ をすごい方は2く一食で食べたりとかする のでそうする とそう150とかいっちゃうんですよ なるほどあれが120とかあるので とかなるほど深袋で1日4袋あま4袋食べ たらま400g確かになるほどそうそんな に食べなくていいですよ今そんな食べなく ていいけれどもあのただそういう方もい ますよっていうお話ですねおお分かりまし たなんかはい目安としてはそういう感じを 目指していただけるとここがもっと増えて はいバランス整いやすいかなっていう ところですねわかりましたはいでも今お酒 を飲んでいないっていうのもあってあの摂 カロリーあと快食もないていうので今 すごく少なくなっています 1300kcalぐらいしか取ってない状 いいですねはいいいのかどうかわかんない ですけどはいでもここ減りすぎちゃうと 代謝が落ちちゃうっていうのがあるんです よねあのこの食事量であの生きていくん だっていう風に体が思っちゃうのであの ああそれ以上食べちゃった時にあじゃこれ は宅分だと思って脂肪になってて増えてい くっていう風になるあので食べなさすぎて も良くないしっていうのはありますはい からもうちょっとはい食べてもお昼とか もうちょっと食べてもまあ大丈夫だし海食 が入ってもはいまあ大丈夫っっていうこと ですねそこでお酒とか飲みすぎなければ 大丈夫 お酒を飲みすぎなければいいですね なるほどお酒を じゃあ今あれですねあんまり食事量この ままであんまり運動結構ランニングとか いっぱいしちゃうと体がきつくなっちゃい ますねなんかあそうなんですよ疲れやすい とかあの風を引きやすいとかそういう方に 行きやすいこのタンパク質とかも運動して たらこの体重あたりタンパク質量今0.7 ってなってるんですけど1.0はい1.2 ぐらいまで取っても大丈夫 なのでへえはいはい気持ちとしてもう1品 ずつぐらいメイン料を増やしても大丈夫で はあるんですよね今運動するのであれば へえじゃあタパ質はもなるほどちょっと 運動を今ちょっとあの長距離のやつは控え てるんですけどはいなんか ちょっと再開したさああとあれなんですよ 僕自転車道くってたんですけどはい自転車 道なくしちゃったんで あの乗ってないんですよね今探さないと いけなくて今あなくしちゃったなくし ちゃったんですかそうそうえそう止めてる 場所は忘れたんですよなんでちょっと困っ てて今はいそうなんですよそんなそんな ことあるんです ねそどこに止めたか忘れちゃって本当に それは大変うんそうなんですだから はい生機が自転車通勤だったんですけど はい自転車移動だったんですけどそれが できなくってちょっとその辺の代謝も落ち てるね多分こう体代謝落ちてるというか エネルギーを使う頻度が下がってるのかな と思ってうんうんえじゃちょっとカが どんどんはいはいどうぞどうぞ今は自転車 じゃなくて何で通勤されてるんですか今 バスで通勤しバスですあバスなんですね はいはいはいはいはいそうなんですねはい 分かりましたうんそうですねじゃ自転車探 すってのもそうですけど他のところで歩く りを増やしたりとかちょっとし隙間運動と かができてでその前後とかなんかちゃんと 運動するのであればその前後にあの プロテインを飲んだりとかあの捕食を取 たりていうのが必要になるんですけど ちょこちょこ運動するならそれよりはおい あの増やすぐらいの気持ちの方がなんか1 個増やすよと かとかそういう感じでも今のところは 大丈夫かなと思いますあありがとうござい ますあそうなんですねプロテインとかをま 飲むとかじゃなくて普通に食事のを増やす と増やすとかはい分かりましたはい ちゃんと運動するならプロテインを飲むっ ていう方法が大事ですでもだったらあの 食事量で調で大丈夫 はい隙間なんで食事料に挑戦したいと思い ますはいそうです隙でバランスタイプなで はあるんですけどあの湿地がやっぱ多く なりがちっていうのがどちらかというと まだ質多いですかいや多くはないですよ 多くはないんですけど今適量なので他の 栄養素に比べると多くなりがちってこと ですねなのでえはいここで海食とかを食べ たらこうカロリーがアップするじゃない ですかそしたらやっぱり快食で脂質増える かなみたいなところはありますよねえ何 食べてました僕脂質えなんか全然食べて ないイメージがあるんですけどめてですね あでもこの時はえっとびっっくりドンキー 朝ドンキーしてる時だったかな面談の時だ からそれもそれそれがなるほどなるほど ごめんなさいなんか朝朝昼晩がちゃんと朝 昼晩この日っていうのが分かるのがその日 だったのであのそこ入れたっていうことな んですけどこれれはレアですねはいこれ からこう記録していただく時に1日って 感じでこう送っていただけると区切りが 分かるというかはいはいそうですよね写真 に写真撮った人が分かるとね分かりやすい ですよねその送ってでくる品さしかわかん ないですで確そうそうなんですねこれどの どの組み合わせで1日なんだろうっていう のがちょっとあったりとかしてあのごめん なさいちょっと私が理解しれなくてそう いやそれはもちろんですよあの ですたありがとうございますはいなので別 にここの支出量はそんなに気にすることは ないですけどでも油断すると増えやすい ぞっていうことです ねわかりましたなるほど 支出って結構すぐ増えますねそれでくと なんか世の中って結構脂質があるものが たくさんいですね質そうそうなんですよね そうなんですよなので あのパ質を置いといてのだとどしても やっぱりあのハンバーグの材料と目玉焼け が来ちゃってるのでやっぱりびっくりドキ の影響がここに来てい るっていうのが%ます ねすごいすねちょっとそれを食べたって だけでもそんなに増えるんですね稽古して 逆に逆に他のものを食べてないっていうの もあるんですけど他になんか加工品を食べ たりとか外食とかをそんなにしてないから ここばっかり目立ってきちゃってるよって いうのは ありますいやいいですねその贅沢なものな んでだったでしょうね人間とって贅沢品な でしょうねそもそもこれて卵を乗せて ハンバーグ食べるって面白いす ねそれは取るわ夜中の普通にしてたら今の 夜中でもそうお肉が別に悪なわけじゃなく てやっぱ挽肉ってお肉の中でも油が多い部 になる はいはいなのであの普通のグリルチキンと かを選んでいただいたりとかっていうこ 選び方を変えてもらえればあの別に外食が ダメて言ってるわけじゃなくて選択方法 っていうんですかねこ選べる時ははいはい 変えていくってのが必要になりますよね うんうんみたい なお魚は取っていただきたいあとお魚が たまたまなかったですねこの あんまりない最近取ってないかもしれない ですねお魚って頻度が減ってるうんどちら かと最近ちょっと少ないうん減ってると 思いますお魚そこまでなかったしあそう ですよねタイミングってのもあると思うん ですけどどちらかというとこっちのこの下 の2つの脂肪さっていうのを多く取って いただきたいっていうのがあってそしたら 大阪の方で油を取る分にはそんなに問題が ないのでお魚とか取り入れていけたらいと か2回とかこう無理のない範囲で取り入れ ていけたらいいのかなっていうのだったり 分かりまし たさ こう外食のチョイスも挽肉系とか揚げ物系 じゃなくてあの鶏肉の定食だったりとかっ ていうのを選べるようになると変わってく るってことですねはいわかりましたはい なるほど 確そうですねで分とかは結構やっぱり自炊 のそのお食事ご自宅で食べてる食事があの 多かったので全然ここら辺は問題なかった かなと思います今回に関してははいうちは あれ塩が結構少なめなんでそうですよね 結構こう味噌汁とかもさんですしあの薄味 そうだなっていう感じで計算をさせて もらったの ででご自宅での食は全 はいありがとうございますはいあの ビタミンミネラルですはいそうです ねビタミンミネラルで言うとここら辺 ビタミンDとかこれキノコとかによく入っ てますねあとB1B2とかがもうちょっと 取れると会社が上がりやすいかなっていう のがあるんですよね赤身肉このB1ビと 赤肉赤肉はいはい脂の とかを選ん で肉と かなるほど カニレバーはなんか壊れですかよくレバー 食べるんですけど最近はいあレバーレバー 食べると結構いろんなところが増えていい ですよあそうなんですねええそうなんです はいで苦手な方が多いのでそんなに進め ないんですけどでもこのこことか見て いただけるとここにもレバー入ってくるこ 入てるなんかもうちょっと下にレバーと 入ってくるしレバー入ってくるでうん本当 だあのレバーあのコンビニに売ってるんす よあそうですよね鳥レバーの似たやつそう そうそうあのセブンにあるんでうんうん あれあれ鳥なんですねあれあれ美味しいん でよく食べるんですよあれなあのはいうん あいいと思いますそれを取り入れて いただいてあはいはいはいはいあそうなん か赤身肉を少し取るっていうのはなんか 難しくて一品追加するって赤身肉だけであ あなんか売ってないなとあすいません確か にどうすればいいミニックハムでもハムと か食べるとあ食塩が増えるじゃないですか あそうですね加工肉になるので食塩が増え ちゃうってのがあるのでなのでそれは レバーでやっぱり解消できるかもしんない ですねこここはあじゃレバー 食はいそうですねあのさ最後にえっとお すめの食材が書いてあるので旅食野菜回が ちょっと野菜がそちょっと少なかったなっ ていうのがあるのでもうちょっと増やした 方がいいよっていうのと魚介類も出てこ なかったのであの食べても大丈夫だよって いうような感じで書かせてもらって ますわかりましたはいこちら見ていただい てどうですかなんか改めて元気になって このもうちょっとこれを気をつけようかな みたいなのってあります かえっとそうですね えっとやっぱ支出っていうのは僕すごい 減ったと思ったんですよけどはいまだ ちょっとこうあなんか少なめかなと思っ たらまだ適量ぐらいなんだと思っってすぐ 入ってくると思いましたはい今でもいい 感じですあの減らし方としてはとてもいい 感じに減ってるのでおいですねちょっとす ね今あの送ってなかったやつ送っときます はい メッセージなかなか毎日送れないのであ 送っちゃった途であの さはいありがとう今写真送りましたはい はい確認あのわにや食べたりと か本当だ すごいがスープ作ってくれ はいあとはま朝は相変わらず卵焼きと おにぎりなんですけどはい はいあと今日ねこのレバーともずくと卵茶 ハリッとほれ草はいあ結構しったり食べ ましたねこういう感じはいはいこれは 昼ご飯ま昼って言ったもはい3時ぐらいに 食べたんですけどはいありがとうござい ますえっとあこん感じの食事にしていけば いいのかなと思ってはいレバーとレとと あとご飯でタスカうん卵も入ってるし みたいな茶だ からそうですねあでもどうえはいこのほれ ソのやつだと野菜がなんだろうキャベツに 比べると重くないかもしれないです刃物 ちょっと軽めなので ああ重くないと言うとあの 例えばさっき言ってたキャベツのハット キャベツとか食べると1袋で 10020とか取れるけれどもこのほれ草 は多分食べても30とか40とかの野菜量 かなっていうのがはいあります おおじゃあもっと食べないとってことです ねはいこれもいいんですけどこれじゃなく てなんかなんてんですか下にキャベツが 入ってて上にコーンが乗ってるようなはい サラダって言ってるじゃないですか はいはいちょっとトマトが一切れ乗ってる ようなああいうの重量が重くていいかなっ ていうのがありますねああそれはあれなん ですかやっぱ重量なんすね なんかなるほどねほれ草 って体に良さそうだなって買ったり旅行食 あでキャベツも旅行食野菜ですかいや キャベツは単色野菜なんですけどそのはい はい体に確かにいいんですよ体にいいん ですけど重さのこと考えの量を増やす ぞっていうところにフォーカスを当てると あのそっちの方がいいよっていうお話です ね ああ六食野菜あ分かりましたじゃ重い方が いいわけですね重いたい野菜うん重たいっ ていうかうん量を食べれますああ分かり まし たちょっとそういう重たい野菜にしていき たいと思い ます えっと旅野菜が何かあんまよく分かって ないですけどなんか妻に聞いたら切っても 色がついてる野菜だって言われたんではい ニンジンとかはいそうです僕旅行食野菜 って言たらニンジンとほれ草しか 思い浮かばないですけど他に何があるん ですか知らない宅で結構取ってらっしゃる 印象だったんですよねえっとはい ブロッコリーとかブロッコリスプラウトと かもいいですし12時スーパあれですね スーパーなんとかスラトですねあれそう そうですはいそうですよねすごいよく取る なと思って見てたのであれは継続して くださブロッコリスプラウトブロッコリー 他には何があとラとかトマトとかラ ピーマンとかあんまないですねへえ ピーマン取ってないですねそれで行くとえ オピーマントマトロロ時々食べますね ブロッコリース そうキャベツは違うんですよねキャベツは キャベツはそうですね薄い単色野菜 ですえあれもですかコーンもですかコは 穀類野菜じゃない ですそっか類 ですそうだったえっと芋と一緒だほ ほとんど 芋は違うんですかね類でもないですか芋は 芋です芋芋は芋 ですやブロッコリスプラトわかりましたP 1 ツレタスはレタスも単色野菜です ねもっと色こい小松なとかはいはいとかは あの緑王食ですね水とかええ へえじゃああれですねなんかそういう コンビニで買あの袋 袋野菜うんうんで も六甲食野菜が含まれてる方がいいって ことなんです ねなんかレタスサラダとかあるんすけど なんこれ意味あんのかなと思ったんですよ なんかいいのかなみたい なレタスサラダだと重量が少ないですよね 絶対キャベツのやつの方が重たい あじゃカップに入ってるキャベツの方と かちの方がいいんですかそういってこと なるとうんうんそうですね へえなるほど えじゃ野菜を増やしましょうたんですけど はいその重量さえ増えれば単色野菜だけ 食べても全然いいんですかそのキャベ ばっかりです300gはいえ比率としては えっと230が単色野菜で120が緑食 野菜なので野菜が多めになことは問題が ないですあそうなんですねあそういうあ そういうことなんですね知なるほど 分かりました1対2ぐらいで考えてけも いいですねはい食野菜が1単色野菜が3の 2と3の1ぐらいってことですねはい 分かりまし た ええ分かりました野菜多め脂質少なめ レバーたくさんです ねお酒飲むお酒があんまり飲まれすぎない です ねあとあれですねお魚の出現がどのくらい お魚取れるかっていう話ですねああ魚はい 分かりましたどうですか選べますかご自宅 はね選択ができないのであれですけど あのそうです ね魚 ってなかなか選択肢難しくないです か その魚 ってえばファミレス行ったらフカメニーっ てなんかないイメージというかコミニって 魚みたいなねなんかお肉とかあるすけど うん はいそは魚はいはいどうぞどうぞはいあの ちっちゃいサバのおろしにみたい なおろしあると思うんですよねあのデリ カップみたいな 丸いおかずシリーズがセイレブンにあって そこにああはいはいはいがあったりするか はいはいていうのがありますわかりました 見てみますはいあとサダに限らずエビとか イカとかそういうものでも大丈夫な魚介類 でも大丈夫 カルあそうなですねあでも大丈夫なので はい あデリカップであのオイルが入ってるから 選んでないんですけどあのブロッコリーと エビと枝豆が入ってるやつあるんですよ はいちょっとあのオリーブオイルのやつ ですね多分あでも全然大丈夫ですよそう何 ですかオリーブオイルが入ってるか やめようかなと思ってたんですけどオイ 入って かであれちょっとあれでれる高いですよね ちょちょ1個1個300円ぐらいするで そうそうなんですよねなんかこれとこれと これを組み合わせてとかやってるとお昼で 1000円ぐらい行くんですねあの コンビニ のそう高いな思っ てなるほどわかりまし たサバとか魚介はエビとかカとかイカとか でもいですねはいえそうやってあのスルメ も含まれますかスルメスルメ以下あの えっとサカみたいなああのおつまみですか そうそうそうですそうです どんなタイミングで食べようとしてるん ですかいやいやあのあのお腹空いた時あ なんかその感触で何かその欲しいもとか 言ってたじゃないですかなんか欲しいも ドライフルーツを探してもなかなか 見つかんないんですよえはいそうですか セブ行ってもないなくてはいはい欲しもま 僕職場の近くでないのかもしれないです けど欲しいもとかあのドライフルーツが あんまなく てあるとしたらあれだったですよ あのあのつまみのあの先スですか先イカ スルメイカそうそうそうスメイカかはいあ 大丈夫ですよそれでも噛む噛んだりするの で結構満腹になるからはいあのはい ちょっと塩分が多いなってことだけ覚え といてもらって水分を取ってもらえると 大丈夫ですああそうですよいやそうなん ですよこのとかからなあと思うんですよね 欲しいのとかあるとめちゃめちゃいいなと 思うんですけどなかなかないもん で分かりましたちょっと えっと重たいというかキャベツですね一体 に野菜魚介 えっとレバーそして脂質 少なめそ飲みすぎずはいはいフとかではい すりました1個ずつで1個ずつでいいです よあのいっぱいやりすぎると分かんなく なるのであのちょっとずつやってき ましょうはい分かりました はいそしたらあとなんか気になることて あります かそうです ね えっとあ運動せずま食事を変えてこう痩せ ていくっていう時 にそのこ置き換えとかなんかこう品目を バランスを変えるでどこまで痩せていく ものなのかなみたいなその目標65ってし てるけど運動もなしでそれは可能なるのか みたいなとか筋肉量上げなくてそれ可能な のかとかそういったの思ったしその食事の 量時減らさなくてもみたいなどうなん でしょう可能ではありますおおでも期間か どうかなっていうそのおお面白いすねええ 3ヶ月やっ て1番増えてる時よりは5kg4kg 5kg減っているすごいですよ ねそでまあと3ヶ月とか半年とか行って 快食とかの回数にもよりますけど減って いけるかなっていうのはありますはい わかりましたござい ますよ楽しみにしてますはいじゃ面白い ですか取り組むのははいはいよかったその 都度計画はね変えていきますけどあのあ こうした方がいいかなみたいなはい談して やっていきましょうねはいわかりました はい筋肉量とか持ちてないからいいですよ ね確かにあそうですねすごくいいと思い ます寄せ方としては うんすごいありがとうございます様で非常 に食事に支えられて 結はい分かりますありがとうござい ますそしたらえっと次またえっと面談のご 予定なんですけど2週間後とかのご予定 いかがですか3月 の真ん中ぐらい えそうですねえっとですねうん 3月の中旬からですねあの はいですよねヨーロッパあの方に2週間 くらい行くんですよ23週間かなはいなの で時差の関係とかがあってちょっと読み づらいんですよね中旬以降ははいでそのま はいチーズとかいっぱい食べてんなって なるかもしれまん ですえちょっとその前にやりましょうはい 12とか13とかどうでしょうあはい 大丈夫ですよお時間いつがいいですか えっとあじゃあ水曜のこの時間とかし ましょうか水曜の12ですねですか はい違た火曜日か曜日ですねどっちですか 101えっと1211でお願いしますあ はいわかりました3月11日火曜日の17 時ですねうんお願いしますはい大丈夫です じゃそちらで予約しておきます ねはいお願いしますなんで ちょっと あのえは取りすぎ取り過ぎは注意ですか ちなみにどうなんだろう取りすぎると支出 が上がりますああやそうなんですね気を つけますちょっとそれ辺をそそれに向けて ちょっと準備しななと思ってますどういう 向こうで選ぶものとかですねあそうですね 私もちょっと今聞いたのであどんなものが あるのかなってのをちょっとリサーチして おきますねありがとうございます助かり ますはいじゃあまた2週間後よろしくお 願いしますはいよろしくお願いします失礼 しますありがとうございました失礼します\n"
     ]
    }
   ],
   "source": [
    "youtube_url= \"https://www.youtube.com/watch?v=7-7FJcah1iA\"\n",
    "\n",
    "loader = YoutubeLoader.from_youtube_url(\n",
    "    youtube_url,\n",
    "    # add_video_info=True,\n",
    "    language=[\"ja\"])\n",
    "\n",
    "# ドキュメントを読み込む\n",
    "documents = loader.load()\n",
    "print(documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# チェーン\u001b[39;00m\n\u001b[32m     19\u001b[39m summary = summary_prompt | llm | StrOutputParser()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m result = \u001b[43msummary\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/langchain_core/runnables/base.py:3022\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3020\u001b[39m             \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3021\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3022\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3023\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3024\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:286\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    276\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    277\u001b[39m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[32m   (...)\u001b[39m\u001b[32m    281\u001b[39m     **kwargs: Any,\n\u001b[32m    282\u001b[39m ) -> BaseMessage:\n\u001b[32m    283\u001b[39m     config = ensure_config(config)\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    285\u001b[39m         ChatGeneration,\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    296\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:786\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    779\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    780\u001b[39m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[32m   (...)\u001b[39m\u001b[32m    783\u001b[39m     **kwargs: Any,\n\u001b[32m    784\u001b[39m ) -> LLMResult:\n\u001b[32m    785\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:643\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    641\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[32m    642\u001b[39m             run_managers[i].on_llm_error(e, response=LLMResult(generations=[]))\n\u001b[32m--> \u001b[39m\u001b[32m643\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    644\u001b[39m flattened_outputs = [\n\u001b[32m    645\u001b[39m     LLMResult(generations=[res.generations], llm_output=res.llm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[32m    646\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[32m    647\u001b[39m ]\n\u001b[32m    648\u001b[39m llm_output = \u001b[38;5;28mself\u001b[39m._combine_llm_outputs([res.llm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:633\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    630\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    631\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    632\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    635\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    636\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    637\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    638\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m         )\n\u001b[32m    640\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    641\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:851\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    849\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    850\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m         result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    854\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    855\u001b[39m         result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:717\u001b[39m, in \u001b[36mBaseChatOpenAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    715\u001b[39m     generation_info = {\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(raw_response.headers)}\n\u001b[32m    716\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m717\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_chat_result(response, generation_info)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:279\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    277\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    278\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m279\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/openai/resources/chat/completions.py:859\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    817\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    819\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    856\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    857\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    858\u001b[39m     validate_response_format(response_format)\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    882\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    883\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    884\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    885\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    886\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    887\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    888\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    889\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    890\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    891\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    892\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    893\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    894\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    895\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    896\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/openai/_base_client.py:1280\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1266\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1267\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1268\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1275\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1276\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1277\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1278\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1279\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1280\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/openai/_base_client.py:957\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[39m\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    955\u001b[39m     retries_taken = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    959\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    960\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    961\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    962\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    963\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/workspaces/light-up-test/.venv/lib/python3.12/site-packages/openai/_base_client.py:1061\u001b[39m, in \u001b[36mSyncAPIClient._request\u001b[39m\u001b[34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[39m\n\u001b[32m   1058\u001b[39m         err.response.read()\n\u001b[32m   1060\u001b[39m     log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1061\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_response(\n\u001b[32m   1064\u001b[39m     cast_to=cast_to,\n\u001b[32m   1065\u001b[39m     options=options,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1069\u001b[39m     retries_taken=retries_taken,\n\u001b[32m   1070\u001b[39m )\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
     ]
    }
   ],
   "source": [
    "doc = documents[0].page_content\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "            openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            azure_deployment=os.getenv(\"ZURE_OPENAI_GPT4_DEPLOYMENT_NAME\"),\n",
    "            openai_api_version=\"2023-09-15-preview\",\n",
    "            temperature=0.5\n",
    "        )\n",
    "\n",
    "summary_prompt_template = \"\"\"\n",
    "以下のYouTube動画の書き起こしをユーザーと管理栄養士に分類した会話に整理してください:\n",
    "{text}\n",
    "\"\"\"\n",
    "\n",
    "summary_prompt = PromptTemplate.from_template(\n",
    "    summary_prompt_template)\n",
    "# チェーン\n",
    "summary = summary_prompt | llm | StrOutputParser()\n",
    "result = summary.invoke(doc)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "            openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            azure_deployment=os.getenv(\"ZURE_OPENAI_GPT4_DEPLOYMENT_NAME\"),\n",
    "            openai_api_version=\"2023-09-15-preview\",\n",
    "            temperature=0.5\n",
    "        )\n",
    "\n",
    "evaluation_prompt_template = \"\"\"\n",
    "以下のユーザーと管理栄養士の会話を評価してください:\n",
    "{text}\n",
    "\"\"\"\n",
    "    \n",
    "evaluation_prompt = PromptTemplate.from_template(\n",
    "    evaluation_prompt_template)\n",
    "\n",
    "# チェーン\n",
    "chain = evaluation_prompt | llm | StrOutputParser()\n",
    "result = chain.invoke(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
